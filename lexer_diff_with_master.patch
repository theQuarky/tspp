diff --git a/src/lexer/Lexer.cpp b/src/lexer/Lexer.cpp
new file mode 100644
index 0000000..4a1046b
--- /dev/null
+++ b/src/lexer/Lexer.cpp
@@ -0,0 +1,17 @@
+#include "Lexer.h"
+
+#include "../common/DebugLog.h"
+
+namespace lexer {
+Lexer::Lexer(const std::string& source)
+    : source_(source), pos_(0), line_(1), col_(1) {}
+
+std::vector<tokens::Token> Lexer::tokenize() {
+  tokens_.clear();
+  errors_.clear();
+  // TODO: Implement tokenization logic here
+  common::DebugLog::info("Lexer::tokenize() called");
+  return tokens_;
+}
+// Helper methods for lexing will be implemented here
+}  // namespace lexer
diff --git a/src/lexer/Lexer.h b/src/lexer/Lexer.h
new file mode 100644
index 0000000..3a345ad
--- /dev/null
+++ b/src/lexer/Lexer.h
@@ -0,0 +1,33 @@
+#pragma once
+#include <string>
+#include <vector>
+
+#include "../common/Error.h"
+#include "../common/Location.h"
+#include "../tokens/Token.h"
+#include "../tokens/TokenFactory.h"
+#include "../tokens/TokenType.h"
+#include "../tokens/TokenUtils.h"
+
+namespace lexer {
+/**
+ * Lexer - Tokenizes TSPP++ source code into tokens.
+ */
+class Lexer {
+ public:
+  Lexer(const std::string& source);
+  std::vector<tokens::Token> tokenize();
+  const std::vector<common::Error>& errors() const {
+    return errors_;
+  }
+
+ private:
+  std::string source_;
+  size_t pos_ = 0;
+  int line_ = 1;
+  int col_ = 1;
+  std::vector<tokens::Token> tokens_;
+  std::vector<common::Error> errors_;
+  // Helper methods for lexing will be added here
+};
+}  // namespace lexer
diff --git a/src/lexer/lexer.cpp b/src/lexer/lexer.cpp
index 417b954..46c54ab 100644
--- a/src/lexer/lexer.cpp
+++ b/src/lexer/lexer.cpp
@@ -1,42 +1,56 @@
-/*****************************************************************************
- * File: lexer.cpp
- * Description: Implementation of main lexer for TSPP language
- *****************************************************************************/
-
 #include "lexer.h"
-
-namespace lexer {
-
-Lexer::Lexer(std::string source, std::string filename)
-    : state_(
-          std::make_shared<LexerState>(std::move(source), std::move(filename))),
-      scanner_(state_) {}
-
-std::vector<tokens::Token> Lexer::tokenize() {
-  while (!state_->isAtEnd()) {
-    tokens::Token token = scanner_.scanToken();
-
-    if (token.isError()) {
-      addError(token);
-      continue;
+#include <cctype>
+
+Lexer::Lexer(const std::string& src) : source(src), pos(0) {}
+
+std::vector<Token> Lexer::tokenize() {
+    std::vector<Token> tokens;
+    while (pos < source.size()) {
+        skipWhitespace();
+        if (pos >= source.size()) break;
+        char c = peek();
+        if (std::isalpha(c) || c == '_') {
+            tokens.push_back(identifier());
+        } else if (std::isdigit(c)) {
+            tokens.push_back(number());
+        } else {
+            // Note: In TSPP++, semicolons (;) are optional at statement boundaries.
+            // The lexer will tokenize ';' as a symbol, but the parser will handle its optionality.
+            tokens.push_back(symbol());
+        }
     }
+    tokens.push_back({TokenType::EndOfFile, ""});
+    return tokens;
+}
 
-    state_->addToken(token);
+char Lexer::peek() const {
+    return pos < source.size() ? source[pos] : '\0';
+}
 
-    if (token.getType() == tokens::TokenType::END_OF_FILE) {
-      break;
-    }
-  }
+char Lexer::get() {
+    return pos < source.size() ? source[pos++] : '\0';
+}
 
-  return state_->getTokens();
+void Lexer::skipWhitespace() {
+    while (pos < source.size() && std::isspace(source[pos])) ++pos;
 }
 
-void Lexer::addError(const tokens::Token &token) {
-  std::string error =
-      "Lexical error at line " + std::to_string(token.getLocation().getLine()) +
-      ", column " + std::to_string(token.getLocation().getColumn()) + ": " +
-      token.getErrorMessage().value_or("Unknown error");
-  errors_.push_back(error);
+Token Lexer::identifier() {
+    size_t start = pos;
+    while (pos < source.size() && (std::isalnum(source[pos]) || source[pos] == '_')) ++pos;
+    std::string value = source.substr(start, pos - start);
+    // TODO: Check for keywords
+    return {TokenType::Identifier, value};
 }
 
-} // namespace lexer
\ No newline at end of file
+Token Lexer::number() {
+    size_t start = pos;
+    while (pos < source.size() && std::isdigit(source[pos])) ++pos;
+    std::string value = source.substr(start, pos - start);
+    return {TokenType::Literal, value};
+}
+
+Token Lexer::symbol() {
+    char c = get();
+    return {TokenType::Symbol, std::string(1, c)};
+}
diff --git a/src/lexer/lexer.h b/src/lexer/lexer.h
index f66ccd6..3fce77a 100644
--- a/src/lexer/lexer.h
+++ b/src/lexer/lexer.h
@@ -1,36 +1,31 @@
-/*****************************************************************************
- * File: lexer.h
- * Description: Main lexer interface for TSPP language
- *****************************************************************************/
-
 #pragma once
-#include "scanner/token_scanner.h"
-#include "state/lexer_state.h"
-#include <memory>
 #include <string>
 #include <vector>
 
-namespace lexer {
+enum class TokenType {
+    Identifier,
+    Keyword,
+    Symbol,
+    Literal,
+    EndOfFile
+};
+
+struct Token {
+    TokenType type;
+    std::string value;
+};
 
 class Lexer {
 public:
-  explicit Lexer(std::string source, std::string filename = "");
-
-  // Process source and return all tokens
-  std::vector<tokens::Token> tokenize();
-
-  // Get any lexical errors that occurred
-  const std::vector<std::string> &getErrors() const { return errors_; }
-
-  // Check if lexical analysis encountered errors
-  bool hasErrors() const { return !errors_.empty(); }
-
+    Lexer(const std::string& src);
+    std::vector<Token> tokenize();
 private:
-  std::shared_ptr<LexerState> state_;
-  TokenScanner scanner_;
-  std::vector<std::string> errors_;
-
-  void addError(const tokens::Token &token);
+    std::string source;
+    size_t pos;
+    char peek() const;
+    char get();
+    void skipWhitespace();
+    Token identifier();
+    Token number();
+    Token symbol();
 };
-
-} // namespace lexer
\ No newline at end of file
diff --git a/src/lexer/patterns/lexer_patterns.h b/src/lexer/patterns/lexer_patterns.h
index 51f122c..61a4bad 100644
--- a/src/lexer/patterns/lexer_patterns.h
+++ b/src/lexer/patterns/lexer_patterns.h
@@ -1,118 +1,15 @@
-// lexer_patterns.h
-/**
- * @file lexer_patterns.h
- * @brief Regular expression patterns and lexer utilities
- *
- * Provides regex patterns and helper functions for lexical analysis:
- * - Token pattern matching
- * - Character classification
- * - Comment handling
- * - Number format validation
- * - String and character literal processing
- */
-
 #pragma once
+// Regex and pattern definitions for lexer
+
 #include <regex>
 #include <string>
-#include <unordered_set>
 
 namespace lexer {
-
-class LexerPatterns {
-public:
-  static const std::regex &getIdentifierPattern() {
-    static const std::regex pattern(R"([a-zA-Z_][a-zA-Z0-9_]*)");
-    return pattern;
-  }
-
-  static const std::regex &getAttributePattern() {
-    // Remove the optional (?:\(([0-9]+)\))? part
-    static const std::regex pattern(
-        R"(#(stack|heap|static|shared|unique|weak|inline|unsafe|aligned)\b)");
-    return pattern;
-  }
-
-  static const std::regex &getNumberPattern() {
-    static const std::regex pattern(
-        R"((?:0[xX][0-9a-fA-F]+(?:_[0-9a-fA-F]+)*)|)"
-        R"((?:0[bB][01]+(?:_[01]+)*)|)"
-        R"((?:[0-9]+(?:_[0-9]+)*(?:\.[0-9]+(?:_[0-9]+)*)?(?:[eE][+-]?[0-9]+(?:_[0-9]+)*)?))");
-    return pattern;
-  }
-
-  static const std::regex &getStringPattern() {
-    static const std::regex pattern(
-        R"("(?:[^"\\]|\\['"\\nrt0]|\\x[0-9a-fA-F]{2}|\\u[0-9a-fA-F]{4})*")");
-    return pattern;
-  }
-
-  static const std::regex &getCharPattern() {
-    static const std::regex pattern(
-        R"('(?:[^'\\]|\\['"\\nrt0]|\\x[0-9a-fA-F]{2}|\\u[0-9a-fA-F]{4})')");
-    return pattern;
-  }
-
-  static const std::regex &getOperatorPattern() {
-    static const std::regex pattern(
-        R"(->|\.|\+\+|--|&&|\|\||==|!=|<=|>=|\+=|-=|\*=|/=|%=|&=|\|=|\^=|<<|>>|\?\?|\?\.|\?|:|[+\-*/%&|^~!<>=@#])");
-    return pattern;
-  }
-
-  // Character Classification
-  static bool isOperatorStart(char c) {
-    static const std::string operatorStarts =
-        "+-*/%&|^~!<>=?:.@#{}()[]"; // Added {}()[]
-    return operatorStarts.find(c) != std::string::npos;
-  }
-
-  static bool isDigitStart(char c) { return std::isdigit(c) || c == '.'; }
-
-  static bool isIdentifierStart(char c) { return std::isalpha(c) || c == '_'; }
-
-  static bool isStringStart(char c) { return c == '"'; }
-
-  static bool isCharStart(char c) { return c == '\''; }
-
-  static bool isWhitespace(char c) { return std::isspace(c); }
-
-  // Attribute Validation
-  static bool isValidAttribute(const std::string &attr) {
-    static const std::unordered_set<std::string> validAttrs = {
-        "#stack",     "#heap",    "#static",  "#shared",   "#unique",
-        "#weak",      "#inline",  "#virtual", "#unsafe",   "#simd",
-        "#target",    "#aligned", "#packed",  "#abstract", "#zerocast",
-        "#const",     "#sizeof",  "#alignof", "#typeof",   "#asm",
-        "#deprecated" // Added this
-    };
-    return validAttrs.count(attr) > 0;
-  }
-
-  // Token Analysis
-  static bool canBeCompound(char c) {
-    static const std::string compoundable = "+-*/%&|^<>=!.?:";
-    return compoundable.find(c) != std::string::npos;
-  }
-
-  static size_t getMaxOperatorLength() { return 3; }
-
-  // Number Validation
-  static bool isNumberStart(const std::string &input, size_t pos);
-
-  // Comment Detection
-  static bool isLineCommentStart(const std::string &input, size_t pos) {
-    return pos + 1 < input.length() && input[pos] == '/' &&
-           input[pos + 1] == '/';
-  }
-
-  static bool isBlockCommentStart(const std::string &input, size_t pos) {
-    return pos + 1 < input.length() && input[pos] == '/' &&
-           input[pos + 1] == '*';
-  }
-
-  static bool isBlockCommentEnd(const std::string &input, size_t pos) {
-    return pos + 1 < input.length() && input[pos] == '*' &&
-           input[pos + 1] == '/';
-  }
-};
-
-} // namespace lexer
\ No newline at end of file
+namespace patterns {
+// Example patterns for identifiers, numbers, strings, operators
+static const std::regex identifier_pattern(R"([a-zA-Z_][a-zA-Z0-9_]*)");
+static const std::regex number_pattern(R"(\d+(\.\d+)?)");
+static const std::regex string_pattern(R"(".*?"|'.*?')");
+static const std::regex operator_pattern(R"([+\-*/=<>!&|^%]+)");
+}  // namespace patterns
+}  // namespace lexer
diff --git a/src/lexer/patterns/token_maps.h b/src/lexer/patterns/token_maps.h
index 52cf372..5a5cade 100644
--- a/src/lexer/patterns/token_maps.h
+++ b/src/lexer/patterns/token_maps.h
@@ -1,221 +1,19 @@
-// token_map_utils.h
-/**
- * @file token_map_utils.h
- * @brief Utility functions for token manipulation and validation
- *
- * This file provides comprehensive utilities for:
- * - Token sequence validation based on grammar rules
- * - Type system compatibility checking
- * - Modifier and attribute validation
- * - Operator classification
- * - Context-aware token analysis
- */
-
 #pragma once
-#include "tokens/token_type.h"
-#include <string>
-#include <unordered_set>
-
-namespace lexer {
-
-class TokenMapUtils {
-public:
-  // Operator Classification
-  static bool isUnaryOperator(const std::string &op, bool prefix = true) {
-    static const std::unordered_set<std::string> prefixOps = {
-        "+", "-", "!", "~", "*", "&", "++", "--", "@"};
-    static const std::unordered_set<std::string> postfixOps = {"++", "--"};
-    return prefix ? prefixOps.count(op) > 0 : postfixOps.count(op) > 0;
-  }
-
-  static bool isBinaryOperator(const std::string &op) {
-    static const std::unordered_set<std::string> binaryOps = {
-        "+",  "-",  "*", "/", "%", "==", "!=", "<", ">",  "<=", ">=",
-        "&&", "||", "&", "|", "^", "<<", ">>", ".", "->", "@"};
-    return binaryOps.count(op) > 0;
-  }
-
-  // Type System
-  static bool isTypeModifier(tokens::TokenType type) {
-    static const std::unordered_set<tokens::TokenType> modifiers = {
-        tokens::TokenType::SHARED, tokens::TokenType::UNIQUE,
-        tokens::TokenType::WEAK, tokens::TokenType::REF};
-    return modifiers.count(type) > 0;
-  }
-
-  static bool isStorageModifier(tokens::TokenType type) {
-    static const std::unordered_set<tokens::TokenType> modifiers = {
-        tokens::TokenType::STACK, tokens::TokenType::HEAP,
-        tokens::TokenType::STATIC};
-    return modifiers.count(type) > 0;
-  }
-
-  static bool isPrimitiveType(tokens::TokenType type) {
-    static const std::unordered_set<tokens::TokenType> primitives = {
-        tokens::TokenType::VOID, tokens::TokenType::INT,
-        tokens::TokenType::FLOAT, tokens::TokenType::BOOLEAN,
-        tokens::TokenType::STRING};
-    return primitives.count(type) > 0;
-  }
-
-  // Function & Class Modifiers
-  static bool isFunctionModifier(tokens::TokenType type) {
-    static const std::unordered_set<tokens::TokenType> modifiers = {
-        tokens::TokenType::INLINE, tokens::TokenType::VIRTUAL,
-        tokens::TokenType::UNSAFE, tokens::TokenType::SIMD,
-        tokens::TokenType::TARGET};
-    return modifiers.count(type) > 0;
-  }
-
-  static bool isClassModifier(tokens::TokenType type) {
-    static const std::unordered_set<tokens::TokenType> modifiers = {
-        tokens::TokenType::ALIGNED, tokens::TokenType::PACKED,
-        tokens::TokenType::ABSTRACT, tokens::TokenType::ZEROCAST};
-    return modifiers.count(type) > 0;
-  }
-
-  // Token Classification
-  static bool isLiteral(tokens::TokenType type) {
-    return type >= tokens::TokenType::LITERAL_BEGIN &&
-           type <= tokens::TokenType::LITERAL_END;
-  }
-
-  static bool isSpecialKeyword(tokens::TokenType type) {
-    return type >= tokens::TokenType::COMPILE_BEGIN &&
-           type <= tokens::TokenType::COMPILE_END;
-  }
-
-  static bool requiresParentheses(tokens::TokenType type) {
-    static const std::unordered_set<tokens::TokenType> needsParams = {
-        tokens::TokenType::ALIGNED, tokens::TokenType::TARGET};
-    return needsParams.count(type) > 0;
-  }
-
-  // Sequence Validation
-  static bool isValidTokenSequence(tokens::TokenType prev,
-                                   tokens::TokenType current) {
-    if (prev == tokens::TokenType::END_OF_FILE ||
-        current == tokens::TokenType::END_OF_FILE) {
-      return false;
-    }
+// Token type and pattern mapping tables
 
-    if (isDeclaration(prev))
-      return canFollowDeclaration(current);
-    if (isType(prev))
-      return canFollowType(current);
-    if (isOperator(prev))
-      return canFollowOperator(prev, current);
-    if (isAccessModifier(prev))
-      return canFollowAccessModifier(current);
-    if (isStorageModifier(prev))
-      return canFollowStorageModifier(current);
-    if (isFunctionModifier(prev))
-      return canFollowFunctionModifier(current);
-    if (isClassModifier(prev))
-      return canFollowClassModifier(current);
-
-    return true;
-  }
-
-  // Type Compatibility
-  static bool isModifierCompatibleWithType(tokens::TokenType modifier,
-                                           tokens::TokenType type) {
-    if (isSmartPointerType(modifier)) {
-      return !isPrimitiveType(type) && type != tokens::TokenType::VOID;
-    }
-
-    if (isStorageModifier(modifier)) {
-      return type != tokens::TokenType::VOID && !isReferenceType(type);
-    }
-
-    if (modifier == tokens::TokenType::REF) {
-      return !isPrimitiveType(type) && type != tokens::TokenType::VOID;
-    }
-
-    if (modifier == tokens::TokenType::ALIGNED) {
-      return !isPrimitiveType(type);
-    }
-
-    if (modifier == tokens::TokenType::UNSAFE) {
-      return isPointerType(type);
-    }
-
-    return true;
-  }
-
-  static std::string getTokenCategory(tokens::TokenType type) {
-    // We need to add checks for delimiters
-    if (isDelimiter(type)) {
-      return "Delimiter";
-    }
-    // Storage modifiers should come before typeModifier check
-    else if (isMemoryManagement(type)) {
-      return "StorageModifier";
-    }
-    // Rest of the existing checks
-    else if (isPrimitiveType(type)) {
-      return "PrimitiveType";
-    } else if (isTypeModifier(type)) {
-      return "TypeModifier";
-    } else if (isFunctionModifier(type)) {
-      return "FunctionModifier";
-    } else if (isClassModifier(type)) {
-      return "ClassModifier";
-    } else if (isLiteral(type)) {
-      return "Literal";
-    } else if (isSpecialKeyword(type)) {
-      return "SpecialKeyword";
-    } else if (isOperator(type)) {
-      return "Operator";
-    } else if (isAccessModifier(type)) {
-      return "AccessModifier";
-    } else if (isDeclaration(type)) {
-      return "Declaration";
-    } else if (isType(type)) {
-      return "Type";
-    } else if (isGeneric(type)) {
-      return "Generic";
-    }
-
-    return "Unknown";
-  }
-
-private:
-  static bool isDeclaration(tokens::TokenType type) {
-    return type >= tokens::TokenType::DECL_BEGIN &&
-           type <= tokens::TokenType::DECL_END;
-  }
-
-  static bool isType(tokens::TokenType type) {
-    return type >= tokens::TokenType::TYPE_BEGIN &&
-           type <= tokens::TokenType::TYPE_END;
-  }
-  static bool isGeneric(tokens::TokenType type) {
-    return type >= tokens::TokenType::GENERIC_BEGIN &&
-           type <= tokens::TokenType::GENERIC_END;
-  }
-  static bool isAccessModifier(tokens::TokenType type) {
-    return type >= tokens::TokenType::ACCESS_BEGIN &&
-           type <= tokens::TokenType::ACCESS_END;
-  }
-
-  static bool isOperator(tokens::TokenType type) {
-    return type >= tokens::TokenType::OPERATOR_BEGIN &&
-           type <= tokens::TokenType::OPERATOR_END;
-  }
+#include <string>
+#include <unordered_map>
 
-  static bool canFollowDeclaration(tokens::TokenType type);
-  static bool canFollowType(tokens::TokenType type);
-  static bool canFollowOperator(tokens::TokenType prev,
-                                tokens::TokenType current);
-  static bool canFollowAccessModifier(tokens::TokenType type);
-  static bool canFollowStorageModifier(tokens::TokenType type);
-  static bool canFollowFunctionModifier(tokens::TokenType type);
-  static bool canFollowClassModifier(tokens::TokenType type);
+#include "../../tokens/TokenType.h"
 
-  static bool isSmartPointerType(tokens::TokenType type);
-  static bool isReferenceType(tokens::TokenType type);
-  static bool isPointerType(tokens::TokenType type);
+namespace lexer {
+namespace patterns {
+// Example operator to token type map
+static const std::unordered_map<std::string, tokens::TokenType> operator_map = {
+    {"+", tokens::TokenType::PLUS},   {"-", tokens::TokenType::MINUS},
+    {"*", tokens::TokenType::STAR},   {"/", tokens::TokenType::SLASH},
+    {"=", tokens::TokenType::EQUALS},
+    // ... add more as needed
 };
-
-} // namespace lexer
+}  // namespace patterns
+}  // namespace lexer
diff --git a/src/lexer/scanner/base/scanner_base.cpp b/src/lexer/scanner/base/scanner_base.cpp
index 7905a32..f3f93b5 100644
--- a/src/lexer/scanner/base/scanner_base.cpp
+++ b/src/lexer/scanner/base/scanner_base.cpp
@@ -1,99 +1,6 @@
-/*****************************************************************************
- * File: scanner_base.cpp
- *
- * Description:
- *   Implementation of the base scanner class for lexical analysis.
- *   Provides core scanning functionality used by specialized scanners.
- *
- * Implementation Details:
- *   - Character matching and advancement
- *   - Token creation and error reporting
- *   - Position tracking and state management
- *
- * Error Handling:
- *   - Null state checking via assertions
- *   - Boundary checking for input
- *   - Error token creation with location info
- *
- * Notes:
- *   - All specialized scanners should inherit from this base
- *   - Maintains shared lexer state across all scanner instances
- *   - Thread-safe through shared_ptr usage
- *****************************************************************************/
-
 #include "scanner_base.h"
-#include <cassert>
-
 namespace lexer {
-
-/*****************************************************************************
- * Constructor Implementation
- *****************************************************************************/
-ScannerBase::ScannerBase(std::shared_ptr<LexerState> state)
-    : state_(std::move(state)) {
-  assert(state_ && "Lexer state cannot be null");
+namespace scanner {
+// No implementation needed for abstract base
 }
-
-/*****************************************************************************
- * Character Inspection Methods
- *****************************************************************************/
-bool ScannerBase::match(char expected) {
-  if (isAtEnd() || peek() != expected) {
-    return false;
-  }
-  advance();
-  return true;
 }
-
-char ScannerBase::peek() const { return state_->getCurrentChar(); }
-
-char ScannerBase::peekNext(int n) const {
-  if (n < 0) {
-    return peek();
-  }
-  return state_->peekNext(n);
-}
-
-bool ScannerBase::isAtEnd() const { return state_->isAtEnd(); }
-
-void ScannerBase::advance() {
-  if (!isAtEnd()) {
-    state_->advance();
-  }
-}
-
-/*****************************************************************************
- * Token Creation Methods
- *****************************************************************************/
-tokens::Token ScannerBase::makeToken(tokens::TokenType type, size_t start,
-                                     size_t length) {
-  if (length == 0) {
-    return makeErrorToken("Invalid token length");
-  }
-
-  std::string_view source = state_->getSource();
-
-  if (start + length > source.length()) {
-    return makeErrorToken("Token position/length exceeds source length");
-  }
-
-  std::string_view lexeme = source.substr(start, length);
-
-  core::SourceLocation location(state_->getLine(), state_->getColumn(),
-                                 state_->getFileName());
-
-  return tokens::Token(type, std::string(lexeme), location);
-}
-
-tokens::Token ScannerBase::makeErrorToken(const std::string &message) {
-  core::SourceLocation location(state_->getLine(), state_->getColumn(),
-                                 state_->getFileName());
-
-  auto lexeme = state_->getCurrentLexeme();
-  std::string errorLexeme =
-      lexeme.empty() ? "" : std::string(lexeme.substr(0, 1));
-
-  return tokens::Token::createError(errorLexeme, location, message);
-}
-
-} // namespace lexer
\ No newline at end of file
diff --git a/src/lexer/scanner/base/scanner_base.h b/src/lexer/scanner/base/scanner_base.h
index 680bf13..bbc5759 100644
--- a/src/lexer/scanner/base/scanner_base.h
+++ b/src/lexer/scanner/base/scanner_base.h
@@ -1,61 +1,13 @@
-/*****************************************************************************
- * File: scanner_base.h
- *
- * Description:
- *   Base scanner class providing core functionality for lexical analysis.
- *   Part of the TSPP compiler's lexical analysis system.
- *
- * Key Features:
- *   - Character inspection and manipulation
- *   - Token creation utilities
- *   - Error handling and reporting
- *   - Shared lexer state management
- *
- * Dependencies:
- *   - lexer_state.h: Lexer state tracking
- *   - tokens.h: Token definitions
- *   - common_types.h: Common type definitions
- *
- * Usage:
- *   Inherit from this class to create specialized scanners for different
- *   token types (identifiers, numbers, operators, etc.)
- *****************************************************************************/
 #pragma once
-#include "lexer/state/lexer_state.h"
-#include "tokens/tokens.h"
-#include <cstddef>
-#include <memory>
+#include <string>
 
+#include "../../../tokens/Token.h"
 namespace lexer {
-
-/**
- * @class ScannerBase
- * @brief Base class for all specialized token scanners
- *
- * Provides common functionality for scanning and token creation:
- * - Character inspection and manipulation
- * - Token creation utilities
- * - Error handling
- * - State management
- */
+namespace scanner {
 class ScannerBase {
-protected:
-  std::shared_ptr<LexerState> state_;
-  ScannerBase(std::shared_ptr<LexerState> state);
-
-  // Utility methods for all scanners
-  bool match(char expected);
-  char peek() const;
-  char peekNext(int n = 1) const;
-  bool isAtEnd() const;
-  void advance();
-
-  // Token creation helpers
-  tokens::Token makeToken(tokens::TokenType type, size_t start, size_t length);
-  tokens::Token makeErrorToken(const std::string &message);
-
-public:
+ public:
   virtual ~ScannerBase() = default;
+  virtual tokens::Token scan(const std::string& src, size_t& pos) = 0;
 };
-
-} // namespace lexer
\ No newline at end of file
+}  // namespace scanner
+}  // namespace lexer
diff --git a/src/lexer/scanner/specialized/identifier_scanner.cpp b/src/lexer/scanner/specialized/identifier_scanner.cpp
index 2915707..bb7e9ac 100644
--- a/src/lexer/scanner/specialized/identifier_scanner.cpp
+++ b/src/lexer/scanner/specialized/identifier_scanner.cpp
@@ -1,233 +1,16 @@
-/*****************************************************************************
- * File: identifier_scanner.cpp
- *
- * Description:
- *   Implementation of identifier and keyword scanning functionality.
- *   Handles lexical analysis of identifiers, keywords, and attributes.
- *****************************************************************************/
-
 #include "identifier_scanner.h"
-#include "tokens/token_type.h"
-#include "tokens/tokens.h"
-#include <algorithm>
-
-namespace lexer {
-
-namespace {
-// Cache the keyword map as a static member for efficiency
-const std::unordered_map<std::string, tokens::TokenType> &getKeywordMapImpl() {
-  static const std::unordered_map<std::string, tokens::TokenType> keywords = {
-      {"let", tokens::TokenType::LET},
-      {"const", tokens::TokenType::CONST},
-      {"function", tokens::TokenType::FUNCTION},
-      {"class", tokens::TokenType::CLASS},
-      {"constructor", tokens::TokenType::CONSTRUCTOR},
-      {"interface", tokens::TokenType::INTERFACE},
-      {"enum", tokens::TokenType::ENUM},
-      {"typedef", tokens::TokenType::TYPEDEF},
-      {"namespace", tokens::TokenType::NAMESPACE},
-      {"if", tokens::TokenType::IF},
-      {"else", tokens::TokenType::ELSE},
-      {"for", tokens::TokenType::FOR},
-      {"of", tokens::TokenType::OF},
-      {"finally", tokens::TokenType::FINALLY},
-      {"while", tokens::TokenType::WHILE},
-      {"do", tokens::TokenType::DO},
-      {"break", tokens::TokenType::BREAK},
-      {"continue", tokens::TokenType::CONTINUE},
-      {"return", tokens::TokenType::RETURN},
-      {"true", tokens::TokenType::TRUE},
-      {"false", tokens::TokenType::FALSE},
-      {"null", tokens::TokenType::NULL_VALUE},
-      {"undefined", tokens::TokenType::UNDEFINED},
-      {"this", tokens::TokenType::THIS},
-      {"void", tokens::TokenType::VOID},
-      {"int", tokens::TokenType::INT},
-      {"float", tokens::TokenType::FLOAT},
-      {"bool", tokens::TokenType::BOOLEAN},
-      {"string", tokens::TokenType::STRING},
-      {"try", tokens::TokenType::TRY},
-      {"catch", tokens::TokenType::CATCH},
-      {"switch", tokens::TokenType::SWITCH},
-      {"case", tokens::TokenType::CASE},
-      {"default", tokens::TokenType::DEFAULT},
-      {"extends", tokens::TokenType::EXTENDS},
-      {"implements", tokens::TokenType::IMPLEMENTS},
-      {"public", tokens::TokenType::PUBLIC},
-      {"private", tokens::TokenType::PRIVATE},
-      {"protected", tokens::TokenType::PROTECTED},
-      {"new", tokens::TokenType::NEW},
-      {"throw", tokens::TokenType::THROW},
-      {"typeof", tokens::TokenType::TYPEOF},
-      {"unsafe", tokens::TokenType::UNSAFE},
-      {"aligned", tokens::TokenType::ALIGNED},
-      {"ref", tokens::TokenType::REF},
-      {"where", tokens::TokenType::WHERE},
-      {"throws", tokens::TokenType::THROWS},
-      {"get", tokens::TokenType::GET},
-      {"set", tokens::TokenType::SET},
-      {"#inline", tokens::TokenType::INLINE},
-      {"#virtual", tokens::TokenType::VIRTUAL},
-      {"#unsafe", tokens::TokenType::UNSAFE},
-      {"#simd", tokens::TokenType::SIMD},
-      {"#target", tokens::TokenType::TARGET},
-      {"#packed", tokens::TokenType::PACKED},
-      {"#abstract", tokens::TokenType::ABSTRACT},
-      {"#zerocast", tokens::TokenType::ZEROCAST},
-      {"cast", tokens::TokenType::CAST}};
-  return keywords;
-}
-} // namespace
-
-/*****************************************************************************
- * Construction
- *****************************************************************************/
-IdentifierScanner::IdentifierScanner(std::shared_ptr<LexerState> state)
-    : ScannerBase(std::move(state)) {}
-
-/*****************************************************************************
- * Public Interface Implementation
- *****************************************************************************/
-tokens::Token IdentifierScanner::scan() {
-  size_t start = state_->getPosition();
-
-  // Scan identifier characters
-  while (!isAtEnd() && (std::isalnum(peek()) || peek() == '_')) {
-    advance();
-  }
-
-  // Directly get source data and length - avoiding intermediate string_view
-  const char *data = state_->getSource().data() + start;
-  size_t length = state_->getPosition() - start;
-
-  // Check if this identifier follows @ token
-  bool afterAt = false;
-  if (start > 0) {
-    char prevChar = state_->getSource()[start - 1];
-    afterAt = (prevChar == '@');
-  }
-
-  if (afterAt) {
-    // Compare directly with string_view from static memory
-    std::string_view id(data, length);
-    if (id == "unsafe" || id == "aligned") {
-      if (id == "unsafe") {
-        return makeToken(tokens::TokenType::UNSAFE, start, length);
-      } else { // aligned
-        // Return just the 'aligned' token
-        auto token = makeToken(tokens::TokenType::ALIGNED, start, length);
-        return token;
-      }
-    }
-  }
-
-  // For identifier type check, use a stable string_view
-  std::string_view identifier(data, length);
-  return makeToken(identifierType(identifier), start, length);
-}
 
-tokens::Token IdentifierScanner::scanAttribute() {
-  size_t start = state_->getPosition();
-  advance(); // Skip #
+#include "../../../tokens/TokenFactory.h"
+#include "../../patterns/lexer_patterns.h"
 
-  size_t nameStart = state_->getPosition(); // Start after #
-
-  // Scan attribute name
-  while (!isAtEnd() && (std::isalpha(peek()) || peek() == '_')) {
-    advance();
-  }
-
-  // Create a direct view of the attribute name
-  const char *data = state_->getSource().data() + nameStart;
-  size_t length = state_->getPosition() - nameStart;
-  std::string_view attrName(data, length);
-
-  // "#inline" | "#virtual" | "#unsafe" | "#simd"
-  //                 | "#const" | "#target"
-  // Map attribute to token type
-  tokens::TokenType type;
-  if (attrName == "stack")
-    type = tokens::TokenType::STACK;
-  else if (attrName == "heap")
-    type = tokens::TokenType::HEAP;
-  else if (attrName == "static")
-    type = tokens::TokenType::STATIC;
-  else if (attrName == "shared")
-    type = tokens::TokenType::SHARED;
-  else if (attrName == "unique")
-    type = tokens::TokenType::UNIQUE;
-  else if (attrName == "weak")
-    type = tokens::TokenType::WEAK;
-  else if (attrName == "inline")
-    type = tokens::TokenType::INLINE;
-  else if (attrName == "virtual") {
-    type = tokens::TokenType::VIRTUAL;
-  } else if (attrName == "unsafe") {
-    type = tokens::TokenType::UNSAFE;
-  } else if (attrName == "simd") {
-    type = tokens::TokenType::SIMD;
-  } else if (attrName == "const") {
-    type = tokens::TokenType::CONST;
-  } else if (attrName == "target") {
-    type = tokens::TokenType::TARGET;
-  } else if (attrName == "asm") {
-    type = tokens::TokenType::ASM;
-    return makeToken(type, start, state_->getPosition() - start);
-  } else if (attrName == "packed") {
-    type = tokens::TokenType::PACKED;
-  } else if (attrName == "abstract") {
-    type = tokens::TokenType::ABSTRACT;
-  } else if (attrName == "aligned") {
-    type = tokens::TokenType::ALIGNED;
-    // Return just the 'aligned' token, let the parser handle the parentheses
-    // and number
-    return makeToken(type, start, state_->getPosition() - start);
-  } else
-    type = tokens::TokenType::ATTRIBUTE;
-
-  // Handle aligned attribute parameters if present
-  if (peek() == '(') {
-    advance(); // Skip (
-    while (!isAtEnd() && peek() != ')') {
-      advance(); // Skip parameter
-    }
-    if (peek() == ')') {
-      advance(); // Skip )
-    }
-  }
-
-  return makeToken(type, start, state_->getPosition() - start);
-}
-
-/*****************************************************************************
- * Private Helper Methods
- *****************************************************************************/
-const std::unordered_map<std::string, tokens::TokenType> &
-IdentifierScanner::getKeywordMap() {
-  return getKeywordMapImpl();
-}
-
-bool IdentifierScanner::validateIdentifier(std::string_view lexeme) {
-  if (lexeme.empty()) {
-    return false;
-  }
-
-  // First character must be letter or underscore
-  if (!std::isalpha(lexeme[0]) && lexeme[0] != '_') {
-    return false;
-  }
-
-  // Remaining characters must be alphanumeric or underscore
-  return std::all_of(lexeme.begin() + 1, lexeme.end(),
-                     [](char c) { return std::isalnum(c) || c == '_'; });
-}
+namespace lexer {
+namespace scanner {
 
-tokens::TokenType IdentifierScanner::identifierType(std::string_view lexeme) {
-  auto &keywords = getKeywordMap();
-  // Convert to string for lookup
-  std::string key(lexeme);
-  auto it = keywords.find(key);
-  return it != keywords.end() ? it->second : tokens::TokenType::IDENTIFIER;
+tokens::Token IdentifierScanner::scan(const std::string& src, size_t& pos) {
+  // Example: scan identifier using regex
+  // TODO: Implement actual logic
+  return tokens::TokenFactory::makeIdentifierToken("example", 1, 1);
 }
 
-} // namespace lexer
\ No newline at end of file
+}  // namespace scanner
+}  // namespace lexer
diff --git a/src/lexer/scanner/specialized/identifier_scanner.h b/src/lexer/scanner/specialized/identifier_scanner.h
index e1ff659..db99881 100644
--- a/src/lexer/scanner/specialized/identifier_scanner.h
+++ b/src/lexer/scanner/specialized/identifier_scanner.h
@@ -1,48 +1,10 @@
-/*****************************************************************************
- * File: identifier_scanner.h
- *
- * Description:
- *   Scanner component for handling identifiers and keywords in the TSPP
- *language. Handles scanning of identifiers, keywords, and attribute names.
- *
- * Features:
- *   - Identifier validation
- *   - Keyword recognition
- *   - Attribute scanning
- *   - Error reporting for invalid identifiers
- *****************************************************************************/
-
 #pragma once
-#include "lexer/scanner/base/scanner_base.h"
-#include "tokens/token_type.h"
-#include "tokens/tokens.h"
-#include <string>
-#include <string_view>
-#include <unordered_map>
-
+#include "../base/scanner_base.h"
 namespace lexer {
-
+namespace scanner {
 class IdentifierScanner : public ScannerBase {
-public:
-  explicit IdentifierScanner(std::shared_ptr<LexerState> state);
-
-  /**
-   * @brief Scan an identifier or keyword token
-   * @return Token representing identifier or keyword
-   */
-  tokens::Token scan();
-
-  /**
-   * @brief Scan an attribute token (starts with #)
-   * @return Token representing the attribute
-   */
-  tokens::Token scanAttribute();
-
-private:
-  static const std::unordered_map<std::string, tokens::TokenType> &
-  getKeywordMap();
-  bool validateIdentifier(std::string_view lexeme);
-  tokens::TokenType identifierType(std::string_view lexeme);
+ public:
+  tokens::Token scan(const std::string& src, size_t& pos) override;
 };
-
-} // namespace lexer
\ No newline at end of file
+}  // namespace scanner
+}  // namespace lexer
diff --git a/src/lexer/scanner/specialized/number_scanner.cpp b/src/lexer/scanner/specialized/number_scanner.cpp
index 4cd09b7..4d9b843 100644
--- a/src/lexer/scanner/specialized/number_scanner.cpp
+++ b/src/lexer/scanner/specialized/number_scanner.cpp
@@ -1,143 +1,17 @@
-/*****************************************************************************
- * File: number_scanner.cpp
- *
- * Description:
- *   Implementation of numeric literal scanning functionality.
- *   Handles decimal, hex, binary, and floating-point numbers.
- *****************************************************************************/
-
 #include "number_scanner.h"
-#include "lexer/patterns/lexer_patterns.h"
-#include <cctype>
-#include <iostream>
-
-namespace lexer {
-
-/*****************************************************************************
- * Construction
- *****************************************************************************/
-NumberScanner::NumberScanner(std::shared_ptr<LexerState> state)
-    : ScannerBase(std::move(state)) {}
-
-/*****************************************************************************
- * Public Interface Implementation
- *****************************************************************************/
-tokens::Token NumberScanner::scan() {
-  size_t start = state_->getPosition();
-
-  // Check for hex or binary prefix
-  if (peek() == '0') {
-    advance(); // consume '0'
-
-    if (peek() == 'x' || peek() == 'X') {
-      advance(); // consume 'x'
-      if (!scanHexDigits()) {
-        return makeErrorToken("Invalid hexadecimal number");
-      }
-      size_t length = state_->getPosition() - start;
-      return makeToken(tokens::TokenType::NUMBER, start, length);
-    }
 
-    if (peek() == 'b' || peek() == 'B') {
-      advance(); // consume 'b'
-      if (!scanBinaryDigits()) {
-        return makeErrorToken("Invalid binary number");
-      }
-      size_t length = state_->getPosition() - start;
-      return makeToken(tokens::TokenType::NUMBER, start, length);
-    }
+#include "../../../tokens/TokenFactory.h"
+#include "../../patterns/lexer_patterns.h"
 
-    // Regular number starting with 0
-    if (std::isdigit(peek())) {
-      if (!scanDigits()) {
-        return makeErrorToken("Invalid decimal number");
-      }
-    }
-  } else {
-    // Regular decimal number
-    if (!scanDigits()) {
-      return makeErrorToken("Invalid decimal number");
-    }
-  }
-
-  // Look for fractional part
-  if (peek() == '.') {
-    advance(); // consume '.'
-    if (!scanDigits()) {
-      return makeErrorToken("Invalid fractional part");
-    }
-  }
-
-  // Look for exponent part
-  if (peek() == 'e' || peek() == 'E') {
-    advance(); // consume 'e'
-
-    // Handle optional sign
-    if (peek() == '+' || peek() == '-') {
-      advance(); // consume sign
-    }
-
-    if (!scanDigits()) {
-      return makeErrorToken("Invalid exponent part");
-    }
-  }
-
-  size_t length = state_->getPosition() - start;
-  return makeToken(tokens::TokenType::NUMBER, start, length);
-}
-
-/*****************************************************************************
- * Private Helper Methods
- *****************************************************************************/
-bool NumberScanner::validateNumber(std::string_view lexeme) {
-  return std::regex_match(lexeme.begin(), lexeme.end(),
-                          LexerPatterns::getNumberPattern());
-}
-
-bool NumberScanner::scanDigits() {
-  bool hasDigit = false;
-  while (std::isdigit(peek()) || peek() == '_') {
-    if (peek() != '_') {
-      hasDigit = true;
-    }
-    advance();
-  }
-  return hasDigit;
-}
-
-bool NumberScanner::scanHexDigits() {
-  bool hasDigit = false;
-  while (std::isxdigit(peek()) || peek() == '_') {
-    if (peek() != '_') {
-      hasDigit = true;
-    }
-    advance();
-  }
-  return hasDigit;
-}
-
-bool NumberScanner::scanBinaryDigits() {
-  bool hasDigit = false;
-  while (peek() == '0' || peek() == '1' || peek() == '_') {
-    if (peek() != '_') {
-      hasDigit = true;
-    }
-    advance();
-  }
-  return hasDigit;
-}
-
-bool NumberScanner::scanExponent() {
-  advance(); // Skip 'e' or 'E'
-
-  // Handle optional sign
-  if (peek() == '+' || peek() == '-') {
-    advance();
-  }
+namespace lexer {
+namespace scanner {
 
-  return scanDigits();
+tokens::Token NumberScanner::scan(const std::string& src, size_t& pos) {
+  // Example: scan number using regex
+  // TODO: Implement actual logic
+  return tokens::TokenFactory::makeLiteralToken(tokens::TokenType::INT, "0", 1,
+                                                1);
 }
 
-bool NumberScanner::scanFraction() { return scanDigits(); }
-
-} // namespace lexer
\ No newline at end of file
+}  // namespace scanner
+}  // namespace lexer
diff --git a/src/lexer/scanner/specialized/number_scanner.h b/src/lexer/scanner/specialized/number_scanner.h
index 86cf99f..c1ce0be 100644
--- a/src/lexer/scanner/specialized/number_scanner.h
+++ b/src/lexer/scanner/specialized/number_scanner.h
@@ -1,33 +1,11 @@
-/*****************************************************************************
- * File: number_scanner.h
- *
- * Description:
- *   Scanner component for handling numeric literals in the TSPP language.
- *   Supports integer, floating-point, hexadecimal, and binary literals.
- *****************************************************************************/
-
 #pragma once
-#include "lexer/scanner/base/scanner_base.h"
-
+// Scanner for numbers
+#include "../base/scanner_base.h"
 namespace lexer {
-
+namespace scanner {
 class NumberScanner : public ScannerBase {
-public:
-  explicit NumberScanner(std::shared_ptr<LexerState> state);
-
-  /**
-   * @brief Scan a numeric token
-   * @return Token representing the scanned number
-   */
-  tokens::Token scan();
-
-private:
-  bool validateNumber(std::string_view lexeme);
-  bool scanDigits();       // Scans sequence of digits
-  bool scanHexDigits();    // Scans sequence of hex digits
-  bool scanBinaryDigits(); // Scans sequence of binary digits
-  bool scanExponent();     // Scans exponent part of floating point
-  bool scanFraction();     // Scans fractional part of floating point
+ public:
+  tokens::Token scan(const std::string& src, size_t& pos) override;
 };
-
-} // namespace lexer
\ No newline at end of file
+}  // namespace scanner
+}  // namespace lexer
diff --git a/src/lexer/scanner/specialized/operator_scanner.cpp b/src/lexer/scanner/specialized/operator_scanner.cpp
index 513e26e..41b968d 100644
--- a/src/lexer/scanner/specialized/operator_scanner.cpp
+++ b/src/lexer/scanner/specialized/operator_scanner.cpp
@@ -1,143 +1,16 @@
-/*****************************************************************************
- * File: operator_scanner.cpp
- * Description: Implementation of operator token scanning functionality.
- *****************************************************************************/
-
 #include "operator_scanner.h"
-#include "lexer/patterns/lexer_patterns.h"
-#include "tokens/token_type.h"
-#include <iostream>
-#include <string_view>
-#include <unordered_map>
-
-namespace lexer {
-
-/*****************************************************************************
- * Operator Token Mapping
- *****************************************************************************/
-namespace {
-const std::unordered_map<std::string_view, tokens::TokenType> operatorMap = {
-    // Arithmetic operators
-    {"+", tokens::TokenType::PLUS},
-    {"-", tokens::TokenType::MINUS},
-    {"*", tokens::TokenType::STAR},
-    {"/", tokens::TokenType::SLASH},
-    {"%", tokens::TokenType::PERCENT},
-    {"?", tokens::TokenType::QUESTION},
-
-    // Braces and parentheses
-    {"{", tokens::TokenType::LEFT_BRACE},
-    {"}", tokens::TokenType::RIGHT_BRACE},
-    {"(", tokens::TokenType::LEFT_PAREN},
-    {")", tokens::TokenType::RIGHT_PAREN},
-    {"[", tokens::TokenType::LEFT_BRACKET},
-    {"]", tokens::TokenType::RIGHT_BRACKET},
-
-    // Bitwise operators
-    {"&", tokens::TokenType::AMPERSAND},
-    {"|", tokens::TokenType::PIPE},
-    {"^", tokens::TokenType::CARET},
-    {"~", tokens::TokenType::TILDE},
-    {">>", tokens::TokenType::RIGHT_SHIFT},
-    {"<<", tokens::TokenType::LEFT_SHIFT},
-
-    // Logical operators
-    {"!", tokens::TokenType::EXCLAIM},
-    {"&&", tokens::TokenType::AMPERSAND_AMPERSAND},
-    {"||", tokens::TokenType::PIPE_PIPE},
-
-    // Comparison operators
-    {"=", tokens::TokenType::EQUALS},
-    {"==", tokens::TokenType::EQUALS_EQUALS},
-    {"!=", tokens::TokenType::EXCLAIM_EQUALS},
-    {"<", tokens::TokenType::LESS},
-    {">", tokens::TokenType::GREATER},
-    {"<=", tokens::TokenType::LESS_EQUALS},
-    {">=", tokens::TokenType::GREATER_EQUALS},
-
-    // Assignment operators
-    {"+=", tokens::TokenType::PLUS_EQUALS},
-    {"-=", tokens::TokenType::MINUS_EQUALS},
-    {"*=", tokens::TokenType::STAR_EQUALS},
-    {"/=", tokens::TokenType::SLASH_EQUALS},
-    {"%=", tokens::TokenType::PERCENT_EQUALS},
-    {"&=", tokens::TokenType::AMPERSAND_EQUALS},
-    {"|=", tokens::TokenType::PIPE_EQUALS},
-    {"^=", tokens::TokenType::CARET_EQUALS},
-
-    // Other operators
-    {"++", tokens::TokenType::PLUS_PLUS},
-    {"--", tokens::TokenType::MINUS_MINUS},
-    {"->", tokens::TokenType::ARROW},
-    {".", tokens::TokenType::DOT},
-    {"@", tokens::TokenType::AT},
-
-    // type assign operator
-    {":", tokens::TokenType::COLON},
-    {",", tokens::TokenType::COMMA},
-    // end of the line
-    {";", tokens::TokenType::SEMICOLON}};
 
-} // namespace
+#include "../../../tokens/TokenFactory.h"
+#include "../../patterns/token_maps.h"
 
-/*****************************************************************************
- * Constructor Implementation
- *****************************************************************************/
-OperatorScanner::OperatorScanner(std::shared_ptr<LexerState> state)
-    : ScannerBase(std::move(state)) {}
-
-/*****************************************************************************
- * Public Methods Implementation
- *****************************************************************************/
-tokens::Token OperatorScanner::scan() {
-  size_t start = state_->getPosition();
-  char firstChar = peek();
-  advance();
-  // Try compound operator first (+=, -=, ++, etc)
-  if (isCompoundOperator(firstChar)) {
-    char nextChar = peek();
-    if (!isAtEnd()) {
-      // Try two-character compound operator
-      std::string compound{firstChar, nextChar};
-      tokens::TokenType compoundType =
-          getOperatorType(std::string_view(compound));
-
-      if (compoundType != tokens::TokenType::ERROR_TOKEN) {
-        advance(); // consume second character
-        return makeToken(compoundType, start, 2);
-      }
-    }
-  }
-
-  // Single character operator
-  tokens::TokenType type = getOperatorType(std::string_view(&firstChar, 1));
-  if (type != tokens::TokenType::ERROR_TOKEN) {
-    return makeToken(type, start, 1);
-  }
-
-  return makeErrorToken("Invalid operator");
-}
-
-/*****************************************************************************
- * Private Helper Methods Implementation
- *****************************************************************************/
-bool OperatorScanner::isCompoundOperator(char c) const {
-  static const std::string compoundable = "+-*/%&|^<>=!.";
-  return compoundable.find(c) != std::string::npos;
-}
-
-bool OperatorScanner::scanCompoundOperator() {
-  char nextChar = peek();
-  if (isAtEnd() || !LexerPatterns::canBeCompound(nextChar)) {
-    return false;
-  }
-  advance();
-  return true;
-}
+namespace lexer {
+namespace scanner {
 
-tokens::TokenType OperatorScanner::getOperatorType(std::string_view lexeme) {
-  auto it = operatorMap.find(lexeme);
-  return it != operatorMap.end() ? it->second : tokens::TokenType::ERROR_TOKEN;
+tokens::Token OperatorScanner::scan(const std::string& src, size_t& pos) {
+  // Example: scan operator using map
+  // TODO: Implement actual logic
+  return tokens::TokenFactory::makeOperatorToken("+", 1, 1);
 }
 
-} // namespace lexer
\ No newline at end of file
+}  // namespace scanner
+}  // namespace lexer
diff --git a/src/lexer/scanner/specialized/operator_scanner.h b/src/lexer/scanner/specialized/operator_scanner.h
index ffc9378..1ab8d9b 100644
--- a/src/lexer/scanner/specialized/operator_scanner.h
+++ b/src/lexer/scanner/specialized/operator_scanner.h
@@ -1,55 +1,13 @@
-/*****************************************************************************
- * File: operator_scanner.h
- * Description: Scanner component for operators in TSPP language.
- *
- * Key Features:
- *  - Single character operator recognition
- *  - Compound operator scanning
- *  - Operator validation
- *****************************************************************************/
-
 #pragma once
-#include "lexer/scanner/base/scanner_base.h"
+#include "../base/scanner_base.h"
 
 namespace lexer {
+namespace scanner {
 
-/**
- * @brief Scanner for operator tokens in TSPP language
- */
 class OperatorScanner : public ScannerBase {
-public:
-  /**
-   * @brief Construct operator scanner with lexer state
-   * @param state Shared lexer state for scanning
-   */
-  explicit OperatorScanner(std::shared_ptr<LexerState> state);
-
-  /**
-   * @brief Scan next operator token from input
-   * @return Token representing scanned operator
-   */
-  tokens::Token scan();
-
-private:
-  /**
-   * @brief Map operator lexeme to corresponding token type
-   * @param lexeme Operator lexeme to map
-   * @return TokenType for operator or ERROR_TOKEN if invalid
-   */
-  tokens::TokenType getOperatorType(std::string_view lexeme);
-
-  /**
-   * @brief Check if character can start compound operator
-   * @param c Character to check
-   * @return true if character can be compound operator start
-   */
-  bool isCompoundOperator(char c) const;
-
-  /**
-   * @brief Try to scan second part of compound operator
-   * @return true if compound operator successfully scanned
-   */
-  bool scanCompoundOperator();
+ public:
+  tokens::Token scan(const std::string& src, size_t& pos) override;
 };
 
-} // namespace lexer
\ No newline at end of file
+}  // namespace scanner
+}  // namespace lexer
diff --git a/src/lexer/scanner/specialized/string_scanner.cpp b/src/lexer/scanner/specialized/string_scanner.cpp
index 31d4d40..98d48e8 100644
--- a/src/lexer/scanner/specialized/string_scanner.cpp
+++ b/src/lexer/scanner/specialized/string_scanner.cpp
@@ -1,138 +1,17 @@
-/*****************************************************************************
- * File: string_scanner.cpp
- * Description: Implementation of string and character literal scanning.
- *****************************************************************************/
-
 #include "string_scanner.h"
-#include <algorithm>
-#include <cctype>
-
-namespace lexer {
-
-/*****************************************************************************
- * Constructor Implementation
- *****************************************************************************/
-StringScanner::StringScanner(std::shared_ptr<LexerState> state)
-    : ScannerBase(std::move(state)) {}
-
-/*****************************************************************************
- * Public Methods Implementation
- *****************************************************************************/
-tokens::Token StringScanner::scanString() {
-  size_t start = state_->getPosition();
-
-  advance(); // Skip opening quote
-
-  // Process string contents
-  while (!isAtEnd() && peek() != '"') {
-    if (peek() == '\\') {
-      std::string escape = scanEscapeSequence();
-      if (escape.empty()) {
-        return makeErrorToken("Invalid escape sequence");
-      }
-    } else if (!validateCharacter(peek())) {
-      return makeErrorToken("Invalid character in string");
-    } else {
-      advance();
-    }
-  }
-
-  // Check for unterminated string
-  if (isAtEnd()) {
-    return makeErrorToken("Unterminated string");
-  }
-
-  advance(); // Skip closing quote
-  return makeToken(tokens::TokenType::STRING_LITERAL, start,
-                   state_->getPosition() - start);
-}
 
-tokens::Token StringScanner::scanCharacter() {
-  size_t start = state_->getPosition();
-  advance(); // Skip opening quote
+#include "../../../tokens/TokenFactory.h"
+#include "../../patterns/lexer_patterns.h"
 
-  // Process character content
-  if (peek() == '\\') {
-    std::string escape = scanEscapeSequence();
-    if (escape.empty()) {
-      return makeErrorToken("Invalid escape sequence");
-    }
-  } else if (!validateCharacter(peek())) {
-    return makeErrorToken("Invalid character literal");
-  } else {
-    advance();
-  }
-
-  // Validate closing quote
-  if (peek() != '\'') {
-    return makeErrorToken("Invalid character literal");
-  }
-
-  advance(); // Skip closing quote
-  return makeToken(tokens::TokenType::CHAR_LITERAL, start,
-                   state_->getPosition() - start);
-}
-
-/*****************************************************************************
- * Private Helper Methods Implementation
- *****************************************************************************/
-std::string StringScanner::scanEscapeSequence() {
-  advance(); // Skip backslash
-
-  // Handle escape sequences
-  switch (peek()) {
-  // Simple escape sequences
-  case '\'':
-  case '"':
-  case '\\':
-  case 'n':
-  case 'r':
-  case 't':
-  case '0': {
-    char c = peek();
-    advance();
-    return std::string(1, c);
-  }
-  // Hex escape sequence
-  case 'x': {
-    advance();
-    std::string hex;
-    for (int i = 0; i < 2 && !isAtEnd() && std::isxdigit(peek()); ++i) {
-      hex += peek();
-      advance();
-    }
-    return (hex.length() == 2 && validateEscapeSequence(hex)) ? hex : "";
-  }
-  // Unicode escape sequence
-  case 'u': {
-    advance();
-    std::string unicode;
-    for (int i = 0; i < 4 && !isAtEnd() && std::isxdigit(peek()); ++i) {
-      unicode += peek();
-      advance();
-    }
-    return (unicode.length() == 4 && validateEscapeSequence(unicode)) ? unicode
-                                                                      : "";
-  }
-  default:
-    return "";
-  }
-}
-
-bool StringScanner::validateCharacter(char c) const {
-  return c >= 32 && c <= 126; // Printable ASCII range
-}
+namespace lexer {
+namespace scanner {
 
-bool StringScanner::validateEscapeSequence(const std::string &sequence) const {
-  // Check hex escape sequence
-  if (sequence.length() == 2) {
-    return std::all_of(sequence.begin(), sequence.end(), ::isxdigit);
-  }
-  // Check unicode escape sequence
-  if (sequence.length() == 4) {
-    return std::all_of(sequence.begin(), sequence.end(), ::isxdigit);
-  }
-  return false;
+tokens::Token StringScanner::scan(const std::string& src, size_t& pos) {
+  // Example: scan string using regex
+  // TODO: Implement actual logic
+  return tokens::TokenFactory::makeLiteralToken(tokens::TokenType::STRING,
+                                                "\"example\"", 1, 1);
 }
 
-} // namespace lexer
\ No newline at end of file
+}  // namespace scanner
+}  // namespace lexer
diff --git a/src/lexer/scanner/specialized/string_scanner.h b/src/lexer/scanner/specialized/string_scanner.h
index e5abf97..304186a 100644
--- a/src/lexer/scanner/specialized/string_scanner.h
+++ b/src/lexer/scanner/specialized/string_scanner.h
@@ -1,62 +1,13 @@
-/*****************************************************************************
- * File: string_scanner.h
- * Description: Scanner component for string and character literals in TSPP.
- *
- * Key Features:
- *  - String literal scanning
- *  - Character literal scanning
- *  - Escape sequence handling
- *  - Character validation
- *****************************************************************************/
-
 #pragma once
-#include "lexer/scanner/base/scanner_base.h"
+#include "../base/scanner_base.h"
 
 namespace lexer {
+namespace scanner {
 
-/**
- * @brief Scanner for string and character literals
- */
 class StringScanner : public ScannerBase {
-public:
-  /**
-   * @brief Construct string scanner with lexer state
-   * @param state Shared lexer state for scanning
-   */
-  explicit StringScanner(std::shared_ptr<LexerState> state);
-
-  /**
-   * @brief Scan string literal token
-   * @return Token representing string literal
-   */
-  tokens::Token scanString();
-
-  /**
-   * @brief Scan character literal token
-   * @return Token representing character literal
-   */
-  tokens::Token scanCharacter();
-
-private:
-  /**
-   * @brief Process escape sequence in string/char literal
-   * @return Valid escape sequence or empty string if invalid
-   */
-  std::string scanEscapeSequence();
-
-  /**
-   * @brief Check if character is valid in string/char literal
-   * @param c Character to validate
-   * @return true if character is valid
-   */
-  bool validateCharacter(char c) const;
-
-  /**
-   * @brief Validate hex/unicode escape sequence
-   * @param sequence Escape sequence to validate
-   * @return true if sequence is valid
-   */
-  bool validateEscapeSequence(const std::string &sequence) const;
+ public:
+  tokens::Token scan(const std::string& src, size_t& pos) override;
 };
 
-} // namespace lexer
\ No newline at end of file
+}  // namespace scanner
+}  // namespace lexer
diff --git a/src/lexer/scanner/token_scanner.cpp b/src/lexer/scanner/token_scanner.cpp
index 52c1bb4..6a8d431 100644
--- a/src/lexer/scanner/token_scanner.cpp
+++ b/src/lexer/scanner/token_scanner.cpp
@@ -1,125 +1,18 @@
-/*****************************************************************************
- * File: token_scanner.cpp
- * Description: Implementation of main token scanner for TSPP lexical analysis
- *****************************************************************************/
 #include "token_scanner.h"
-#include "core/common/common_types.h"
 
 namespace lexer {
+namespace scanner {
 
-/*****************************************************************************
- * Constructor Implementation
- *****************************************************************************/
-TokenScanner::TokenScanner(std::shared_ptr<LexerState> state)
-    : state_(state), identifierScanner_(state), numberScanner_(state),
-      operatorScanner_(state), stringScanner_(state) {}
+TokenScanner::TokenScanner() {}
 
-/*****************************************************************************
- * Public Methods Implementation
- *****************************************************************************/
-tokens::Token TokenScanner::scanToken() {
-  skipWhitespace();
-
-  if (state_->isAtEnd()) {
-    return makeEndToken();
-  }
-
-  if (checkComment()) {
-    return scanToken();
-  }
-
-  char c = state_->getCurrentChar();
-
-  // Handle string literals
-  if (c == '"') {
-    return stringScanner_.scanString();
-  }
-
-  // Handle character literals
-  if (c == '\'') {
-    return stringScanner_.scanCharacter();
-  }
-
-  // Handle numbers (including decimals)
-  if (std::isdigit(c) || (c == '.' && std::isdigit(state_->peekNext()))) {
-    return numberScanner_.scan();
-  }
-
-  // Handle identifiers and keywords
-  if (std::isalpha(c) || c == '_') {
-    return identifierScanner_.scan();
-  }
-
-  // Handle attributes
-  if (c == '#') {
-    return identifierScanner_.scanAttribute();
-  }
-
-  // Handle operators and other symbols
-  return operatorScanner_.scan();
-}
-
-/*****************************************************************************
- * Private Helper Methods Implementation
- *****************************************************************************/
-void TokenScanner::skipWhitespace() {
-  while (!state_->isAtEnd()) {
-    char c = state_->getCurrentChar();
-    if (std::isspace(c)) {
-      if (c == '\n') {
-        state_->newLine();
-      } else {
-        state_->advance();
-      }
-    } else {
-      break;
-    }
-  }
-}
-
-bool TokenScanner::checkComment() {
-  if (state_->getCurrentChar() == '/') {
-    if (state_->peekNext(1) == '/') {
-      skipLineComment();
-      return true;
-    }
-    if (state_->peekNext(1) == '*') {
-      skipBlockComment();
-      return true;
-    }
-  }
-  return false;
-}
-
-void TokenScanner::skipLineComment() {
-  while (!state_->isAtEnd() && state_->getCurrentChar() != '\n') {
-    state_->advance();
-  }
-}
-
-void TokenScanner::skipBlockComment() {
-  state_->advance(); // Skip /
-  state_->advance(); // Skip *
-
-  while (!state_->isAtEnd()) {
-    if (state_->getCurrentChar() == '*' && state_->peekNext(1) == '/') {
-      state_->advance(); // Skip *
-      state_->advance(); // Skip /
-      return;
-    }
-
-    if (state_->getCurrentChar() == '\n') {
-      state_->newLine();
-    } else {
-      state_->advance();
-    }
-  }
-}
-
-tokens::Token TokenScanner::makeEndToken() {
-  core::SourceLocation location(state_->getLine(), state_->getColumn(),
-                                 state_->getFileName());
-  return tokens::Token(tokens::TokenType::END_OF_FILE, "", location);
+std::vector<tokens::Token> TokenScanner::scanAll(const std::string& src) {
+  // TODO: Implement logic to use specialized scanners
+  std::vector<tokens::Token> tokens;
+  // Example: just call identifier scanner for now
+  size_t pos = 0;
+  tokens.push_back(idScanner_.scan(src, pos));
+  return tokens;
 }
 
-} // namespace lexer
\ No newline at end of file
+}  // namespace scanner
+}  // namespace lexer
diff --git a/src/lexer/scanner/token_scanner.h b/src/lexer/scanner/token_scanner.h
index a326d5e..e78d0b6 100644
--- a/src/lexer/scanner/token_scanner.h
+++ b/src/lexer/scanner/token_scanner.h
@@ -1,39 +1,26 @@
-/*****************************************************************************
- * File: token_scanner.h
- * Description: Main scanner that coordinates specialized scanners for TSPP
- *lexical analysis
- *****************************************************************************/
 #pragma once
+#include <string>
+#include <vector>
+
+#include "../../tokens/Token.h"
+#include "../state/lexer_state.h"
 #include "specialized/identifier_scanner.h"
 #include "specialized/number_scanner.h"
 #include "specialized/operator_scanner.h"
 #include "specialized/string_scanner.h"
-#include <memory>
-
 namespace lexer {
-
+namespace scanner {
 class TokenScanner {
-public:
-  explicit TokenScanner(std::shared_ptr<LexerState> state);
+ public:
+  TokenScanner();
+  std::vector<tokens::Token> scanAll(const std::string& src);
 
-  /**
-   * @brief Scan next token from input
-   * @return Next token in the input stream
-   */
-  tokens::Token scanToken();
-
-private:
-  std::shared_ptr<LexerState> state_;
-  IdentifierScanner identifierScanner_;
-  NumberScanner numberScanner_;
-  OperatorScanner operatorScanner_;
-  StringScanner stringScanner_;
-
-  void skipWhitespace();
-  bool checkComment();
-  void skipLineComment();
-  void skipBlockComment();
-  tokens::Token makeEndToken();
+ private:
+  IdentifierScanner idScanner_;
+  NumberScanner numScanner_;
+  OperatorScanner opScanner_;
+  StringScanner strScanner_;
+  // ... add more as needed
 };
-
-} // namespace lexer
\ No newline at end of file
+}  // namespace scanner
+}  // namespace lexer
diff --git a/src/lexer/state/lexer_state.cpp b/src/lexer/state/lexer_state.cpp
index ca8aeb4..911bfda 100644
--- a/src/lexer/state/lexer_state.cpp
+++ b/src/lexer/state/lexer_state.cpp
@@ -1,134 +1,15 @@
-/*****************************************************************************
- * File: lexer_state.cpp
- * Description: Implementation of LexerState class providing source code
- *navigation and token collection functionality.
- *****************************************************************************/
-
 #include "lexer_state.h"
-
+// Lexer state implementation
 namespace lexer {
-
-/*****************************************************************************
- * Source Inspection Methods
- *****************************************************************************/
-
-std::string_view LexerState::getCurrentLexeme() const {
-  if (position_ >= source_.length()) {
-    return std::string_view();
-  }
-  return std::string_view(source_).substr(position_);
-}
-
-char LexerState::getCurrentChar() const {
-  // position_ is unsigned, so position_ < 0 is always false
-  if (position_ >= source_.length()) {
-    return '\0';
-  }
-  return source_[position_];
-}
-
-char LexerState::peekNext(int n) const {
-  // Handle negative lookhead
-  if (n < 0) {
-    return getCurrentChar();
-  }
-
-  // Calculate peek position and bounds check
-  size_t peek_pos = position_ + n;
-  if (peek_pos >= source_.length()) {
-    return '\0';
-  }
-  return source_[peek_pos];
-}
-
-bool LexerState::match(char expected) {
-  if (isAtEnd() || getCurrentChar() != expected) {
-    return false;
-  }
-  advance();
-  return true;
-}
-
-std::string_view LexerState::getLineContent() const {
-  // Find start of current line
-  size_t lineStart = source_.rfind('\n', position_);
-  if (lineStart == std::string::npos) {
-    lineStart = 0;
-  } else {
-    lineStart++;  // Skip newline character
-  }
-
-  // Find end of current line
-  size_t lineEnd = source_.find('\n', position_);
-  if (lineEnd == std::string::npos) {
-    lineEnd = source_.length();
-  }
-
-  return std::string_view(source_).substr(lineStart, lineEnd - lineStart);
-}
-
-/*****************************************************************************
- * State Management Methods
- *****************************************************************************/
-
-void LexerState::advance(size_t count) {
-  if (count == 0) return;
-
-  // Advance position and track columns, handling tabs
-  for (size_t i = 0; i < count && !isAtEnd(); ++i) {
-    if (getCurrentChar() == '\t') {
-      column_ += 4;  // Use 4 spaces per tab
+namespace state {
+void LexerState::advance(char c) {
+    ++pos_;
+    if (c == '\n') {
+        ++line_;
+        col_ = 1;
     } else {
-      column_++;
-    }
-    position_++;
-  }
-}
-
-void LexerState::newLine() {
-  if (position_ >= source_.length()) {
-    return;
-  }
-
-  // Update line tracking
-  line_++;
-  column_ = 1;
-  position_++;
-
-  // Add implicit semicolon if needed (automatic semicolon insertion)
-  if (!tokens_.empty()) {
-    const auto &lastToken = tokens_.back();
-    if (lastToken.getType() != tokens::TokenType::SEMICOLON &&
-        lastToken.getType() != tokens::TokenType::LEFT_BRACE &&
-        lastToken.getType() != tokens::TokenType::RIGHT_BRACE) {
-      addToken(tokens::Token(tokens::TokenType::SEMICOLON, ";",
-                             core::SourceLocation(line_ - 1, column_)));
+        ++col_;
     }
-  }
-}
-
-void LexerState::addToken(tokens::Token token) {
-  // Validate token location
-  assert(token.getLocation().getLine() <= line_);
-  assert(token.getLocation().getColumn() <= column_);
-
-  tokens_.push_back(std::move(token));
 }
-
-void LexerState::reset() {
-  position_ = 0;
-  line_ = 1;
-  column_ = 1;
-  tokens_.clear();
 }
-
-/*****************************************************************************
- * State Query Methods
- *****************************************************************************/
-
-const tokens::Token &LexerState::getLastToken() const {
-  assert(!tokens_.empty() && "Cannot get last token from empty collection");
-  return tokens_.back();
 }
-
-}  // namespace lexer
\ No newline at end of file
diff --git a/src/lexer/state/lexer_state.h b/src/lexer/state/lexer_state.h
index f89e0f7..1cdd13a 100644
--- a/src/lexer/state/lexer_state.h
+++ b/src/lexer/state/lexer_state.h
@@ -1,137 +1,18 @@
-/*****************************************************************************
- * File: lexer_state.h
- * Description: Maintains lexer state during tokenization process.
- * Manages source code position, line/column tracking, and token collection.
- *****************************************************************************/
-
 #pragma once
-#include "../../tokens/tokens.h"
-#include <cassert>
 #include <string>
-#include <vector>
-
 namespace lexer {
-
-/**
- * @class LexerState
- * @brief Manages lexer state during tokenization process
- *
- * Provides functionality for:
- * - Source code navigation and character inspection
- * - Position and line/column tracking
- * - Token collection and management
- * - Error location reporting
- */
+namespace state {
 class LexerState {
 public:
-  /**
-   * @brief Constructs lexer state with source code
-   * @param source Source code to tokenize
-   * @param fileName Source file name for error reporting
-   */
-  LexerState(std::string source, std::string fileName)
-      : source_(std::move(source)), fileName_(std::move(fileName)),
-        position_(0), line_(1), column_(1), tokens_() {}
-
-  /*****************************************************************************
-   * Source Inspection Methods
-   *****************************************************************************/
-
-  /**
-   * @brief Get remaining source from current position
-   * @return View of remaining unprocessed source
-   */
-  std::string_view getCurrentLexeme() const;
-
-  /**
-   * @brief Get current character under cursor
-   * @return Current character or '\0' if at end
-   */
-  char getCurrentChar() const;
-
-  /**
-   * @brief Look ahead in source without advancing
-   * @param n Number of characters to look ahead (negative returns current char)
-   * @return Character at position + n or '\0' if out of bounds
-   */
-  char peekNext(int n = 0) const;
-
-  /**
-   * @brief Try to match expected character
-   * @param expected Character to match
-   * @return true if matched and advanced, false otherwise
-   */
-  bool match(char expected);
-
-  /**
-   * @brief Get current line content for error reporting
-   * @return View of current line in source
-   */
-  std::string_view getLineContent() const;
-
-  /*****************************************************************************
-   * State Management Methods
-   *****************************************************************************/
-
-  /**
-   * @brief Advance cursor by specified amount
-   * @param count Number of positions to advance
-   * @note Handles tabs for column tracking
-   */
-  void advance(size_t count = 1);
-
-  /**
-   * @brief Handle line break and automatic semicolon insertion
-   */
-  void newLine();
-
-  /**
-   * @brief Add token to collection
-   * @param token Token to add (moved into collection)
-   */
-  void addToken(tokens::Token token);
-
-  /**
-   * @brief Reset lexer state to initial conditions
-   */
-  void reset();
-
-  /*****************************************************************************
-   * State Query Methods
-   *****************************************************************************/
-
-  /**
-   * @brief Check if reached end of source
-   */
-  bool isAtEnd() const { return position_ > source_.length(); }
-
-  /**
-   * @brief Check if any tokens collected
-   */
-  bool hasTokens() const { return !tokens_.empty(); }
-
-  /**
-   * @brief Get last collected token
-   * @return Reference to last token
-   * @pre hasTokens() must be true
-   */
-  const tokens::Token &getLastToken() const;
-
-  // Basic accessors
-  const std::string &getSource() const { return source_; }
-  const std::string &getFileName() const { return fileName_; }
-  size_t getPosition() const { return position_; }
-  unsigned int getLine() const { return line_; }
-  unsigned int getColumn() const { return column_; }
-  const std::vector<tokens::Token> &getTokens() const { return tokens_; }
-
+    LexerState() : pos_(0), line_(1), col_(1) {}
+    size_t pos() const { return pos_; }
+    int line() const { return line_; }
+    int col() const { return col_; }
+    void advance(char c);
 private:
-  std::string source_;                ///< Source code being tokenized
-  std::string fileName_;              ///< Source file name for errors
-  size_t position_;                   ///< Current position in source
-  unsigned int line_;                 ///< Current line number (1-based)
-  unsigned int column_;               ///< Current column number (1-based)
-  std::vector<tokens::Token> tokens_; ///< Collected tokens
+    size_t pos_;
+    int line_;
+    int col_;
 };
-
-} // namespace lexer
\ No newline at end of file
+}
+}
